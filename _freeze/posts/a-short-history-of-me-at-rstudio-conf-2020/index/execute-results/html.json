{
  "hash": "c1f550b6dc9e297b72fc2c40fefe7419",
  "result": {
    "markdown": "---\ntitle: A short history of me at rstudio::conf 2020\nauthor: Sam Albers\ndate: '2020-02-11'\nslug: a-short-history-of-me-at-rstudio-conf-2020\ncategories:\n  - R\n  - RStudio\ntags: []\ndescription: ''\nfeatured: ''\nfeaturedalt: ''\nfeaturedpath: ''\nlinktitle: ''\ntype: post\n---\n\n\n\n\n\n\nIn January, I was lucky enough to attend the 2020 edition of RStudio::conf. Perhaps predictably, the conference and workshops were exceptional and to see all the wonderful things that folks in the R community are capable of was quite inspiring. People are really quite clever. Attending the tidy dev day was such a nice epilogue to the conference because after spending so much time listening to people talk about _their_ code, I was pretty keen to crack open R and have at it myself. Before I lose everything from the conference to memory leaks, I am going to try to catalogue a few things that I learned at the conference by trying to weave them together into a single workflow.\n\n## A brief detour about where to get these packages\nSeveral of the packages that I am using here are at development stages and aren't yet on CRAN. I'm including the installation instructions here but eventually this process should be as easy as the typical `install.packages`. For `ggtext`, which isn't on CRAN, we install it (and the dev version of `ggplot2`) from GitHub:\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github('wilkelab/ggtext')\n```\n:::\n\n\nOther packages that I am using are loaded here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fs)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(arrow)\nlibrary(ggtext)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(here)\nlibrary(stringr)\nlibrary(glue)\n```\n:::\n\n## The `arrow` package\n\nOne of my main goals at the conference was to find out new ways of dealing with very big flat files. I work in an environment where big flat files are sort of our only option. Adding them to a proper database is not currently possible but I was hopeful that maybe the [Apache Arrow project](https://arrow.apache.org/) might offer up some solutions. I was not disappointed. Neal Richardson with [UrsaLabs](https://ursalabs.org/) gave a great [presentation](https://enpiar.com/talks/rstudio-conf-2020/#1) on the status of the project with a specific focus on the R package `arrow`. \n\nHere I am mostly parroting what Neal did with his presentation just replacing taxi data with Canadian hydrometric data. Whether we are provisioned data that way or create it ourselves, consider data organized in a hierarchical folder structure. Here at the top level we have Canadian `province`:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n/Users/samalbers/_dev/gh_repos/samalbers.science/data/rivers-data\n├── AB\n├── BC\n├── NL\n├── SK\n└── YT\n```\n:::\n:::\n\nwithin each `province` folder we have `year`:\n  \n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n/Users/samalbers/_dev/gh_repos/samalbers.science/data/rivers-data/AB\n└── 2017\n```\n:::\n:::\n\nwithin each `year` folder we have `month` \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n/Users/samalbers/_dev/gh_repos/samalbers.science/data/rivers-data/AB/2017\n├── 01\n├── 02\n├── 03\n├── 04\n├── 05\n├── 06\n├── 07\n├── 08\n├── 09\n├── 10\n├── 11\n└── 12\n```\n:::\n:::\n\n\nand finally within that directory you actually have your data file:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n/Users/samalbers/_dev/gh_repos/samalbers.science/data/rivers-data/AB/2017/01\n└── rivers.parquet\n```\n:::\n:::\n\n\nNormally in this situation my approach would be to do some sort of iterative process over each file (mind you still making use of `arrow` to read the parquet file):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_rivs <- list.files(here('data/rivers-data/'), pattern = '*.parquet', recursive = TRUE, full.names = TRUE) %>% \n  map_dfr(read_parquet)\n```\n:::\n\n\nFrom there we might execute some typical sequence designed to filter our data down to a more manageable size.  \n\n::: {.cell}\n\n```{.r .cell-code}\ndf_rivs %>% \n  filter(year(Date) == 2017) %>% \n  filter(Parameter == 'Flow') %>% \n  arrange(Date)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 309,314 × 5\n   STATION_NUMBER Date       Parameter  Value Symbol\n   <chr>          <date>     <chr>      <dbl> <chr> \n 1 05AA008        2017-01-01 Flow       1.75  B     \n 2 05AA024        2017-01-01 Flow       8.67  <NA>  \n 3 05AA035        2017-01-01 Flow       1.56  B     \n 4 05AC003        2017-01-01 Flow       0.954 B     \n 5 05AC012        2017-01-01 Flow       0.736 B     \n 6 05AC941        2017-01-01 Flow       1.03  <NA>  \n 7 05AD003        2017-01-01 Flow       3.77  B     \n 8 05AD007        2017-01-01 Flow      24.6   B     \n 9 05AE027        2017-01-01 Flow       4.81  B     \n10 05AG006        2017-01-01 Flow      24.7   B     \n# … with 309,304 more rows\n```\n:::\n:::\n\n\nWhat we learned in Neal's presentation was the magic of the `open_dataset` function and specifically its ability to map hierarchical directory structure to virtual columns in your data. If we read just one parquet file, it is apparent that there aren't any `province`, `year` or `month` columns:\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nread_parquet(here('data/rivers-data/AB/2017/01/rivers.parquet'))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3,131 × 5\n   STATION_NUMBER Date       Parameter  Value Symbol\n * <chr>          <date>     <chr>      <dbl> <chr> \n 1 05AA008        2017-01-01 Flow       1.75  B     \n 2 05AA024        2017-01-01 Flow       8.67  <NA>  \n 3 05AA035        2017-01-01 Flow       1.56  B     \n 4 05AC003        2017-01-01 Flow       0.954 B     \n 5 05AC012        2017-01-01 Flow       0.736 B     \n 6 05AC941        2017-01-01 Flow       1.03  <NA>  \n 7 05AD003        2017-01-01 Flow       3.77  B     \n 8 05AD007        2017-01-01 Flow      24.6   B     \n 9 05AE027        2017-01-01 Flow       4.81  B     \n10 05AG006        2017-01-01 Flow      24.7   B     \n# … with 3,121 more rows\n```\n:::\n:::\n\n\nInstead, if we assign partitions, using a vector based on the directory structure, `open_dataset` can use that information to efficiently subset a larger dataset. \n\n::: {.cell}\n\n```{.r .cell-code}\nrivs <- open_dataset(here('data/rivers-data/'), partitioning = c('province','year', 'month'))\nrivs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFileSystemDataset with 60 Parquet files\nSTATION_NUMBER: string\nDate: date32[day]\nParameter: string\nValue: double\nSymbol: string\nprovince: string\nyear: int32\nmonth: int32\n\nSee $metadata for additional Schema metadata\n```\n:::\n:::\n\n\nBest of all, the `select`, `filter`, `group_by` and `rename` dplyr verbs are implemented much like `dbplyr` and your query is executed lazily taking advantage of both the directory structure and the parquet files. \n\n::: {.cell}\n\n```{.r .cell-code}\nriver_data <- rivs %>% \n  filter(year == 2017) %>% \n  filter(province %in% c('BC', 'YT', 'AB', 'SK', 'NL')) %>% \n  filter(Parameter == 'Flow') %>% \n  group_by(STATION_NUMBER, province) %>% \n  collect() %>% \n  arrange(Date)\n```\n:::\n\n\nWhile YMMV depending on the size of your data, using folder structure is a nifty way to only access the data we actually need. The Apache Arrow project, and for R users the `arrow` package, are proceeding very nicely. Now that we have efficiently pared down our river flow data, the next exciting thing I want to explore is some really cool developments in the `ggplot2` sphere.\n\n## The `ggtext` package\n\nThe `ggtext` package by Claus Wilke provides much improved rendering support for `ggplot2`. What feels like should a simple task (e.g. colour some portion of text) is sometimes quite onerous in `ggplot2`. Though the package is still in its infancy, `ggtext` is breaking trail on making these steps much easier by providing a mini markdown engine directly inside `ggplot2`. After audible _ohhs_ and _ahhs_ from the crowd while demoing `ggtext`, Claus observed \"I can see this fills a need\". Already it provides some support for markdown and html rendering.\n\n<center><img src=\"https://media.giphy.com/media/vMEjhlxsBR7Fe/giphy.gif\"/></center>\n\nSo how can we use it to better visualize our river data? Because `ggtext` has some minimal html rendering, we can actually include images right inside the ggplot call. My idea was to try and see if I could include provincial flags as axes labels in the plot. This requires steps to:\n\n- get the files\n- extract the province name from the file name\n- create a new column in our rivers data because the provinces aren't labelled in the same way\n- glue the image names with the html snippets \n\nI won't go into too much detail but here are the steps:\n\n### Get the Data\n\n::: {.cell}\n\n```{.r .cell-code}\ndir.create(\"data/flags\")\n\ndownload.file(\"https://cdn.britannica.com/40/5440-004-BE91E74F/Flag-Alberta.jpg\", destfile = \"data/flags/AB.jpeg\")\ndownload.file(\"https://cdn.britannica.com/63/5263-004-1C2B7CDE/Flag-Yukon-Territory.jpg\", destfile = \"data/flags/YT.jpeg\")\ndownload.file(\"https://cdn.britannica.com/18/3918-004-9D01BB0E/Flag-Saskatchewan.jpg\", destfile = \"data/flags/SK.jpeg\")\ndownload.file(\"https://cdn.britannica.com/92/2992-004-54C721CF/Flag-Newfoundland-and-Labrador.jpg\", destfile = \"data/flags/NL.jpeg\")\ndownload.file(\"https://cdn.britannica.com/77/6877-004-26251B48/Flag-British-Columbia.jpg\", destfile = \"data/flags/BC.jpeg\")\n```\n:::\n\n\n### Extract Province\n\n::: {.cell}\n\n```{.r .cell-code}\nflag_paths <- dir_ls(here('data/flags'), glob = '*.jpeg')\n```\n:::\n\n\n\n### Create the Image Tags\n\n::: {.cell}\n\n```{.r .cell-code}\nimg_tags <- glue(\"<img src='{flag_paths}' width='100' />\")\nnames(img_tags) <- basename(path_ext_remove(flag_paths))\n```\n:::\n\n\nWe now have a named vector, which sources the appropriate provincial flag and is ready to render. This is accomplished by supplying the `img_tags` vector to the scale of your choice (here `scale_x_discrete`). `ggplot2` knows how to actually render via `ggtext::element_markdown`. Otherwise we can simply treat this like any other ggplot. Here we are also calculating the annual sum of flows by each value of `STATION_NUMBER`.\n\n::: {.cell}\n\n```{.r .cell-code}\nannual_flow <- river_data %>% \n  group_by(STATION_NUMBER, province) %>%\n  summarise(annual_flow = sum(Value, na.rm = TRUE))\n\nannual_flow %>% \n  ggplot(aes(x = province, y = annual_flow)) +\n  geom_point() +\n  scale_x_discrete(name = NULL, labels = img_tags) +\n  theme(axis.text.x = element_markdown(color = 'black', size = 11))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\nSo I think this is pretty cool! We have images in the axes. AFAIK, this was previously impossible. Unfortunately this isn't a particularly informative nor a nice looking plot. The next step in the workflow is to change that. \n\n## Design Nicer Plots\nRStudio::conf had a thread of design thinking running through the workshops and conference. From the tidyverse's near obsession with the design of their api to the inclusion of a live episode of Not So Standard deviation as a keynote, thinking about data science from a design perspective was a key theme that emerged for me. One example of this was [Will Chase's](https://twitter.com/W_R_Chase) wonderful talk on the [Glamour of Graphics](https://www.williamrchase.com/slides/assets/player/KeynoteDHTMLPlayer.html#0). Will presented some very thoughtful approaches to creating better visualizations. I am going to ~~butcher~~ apply some of those approaches to our plot above. \n\n### Hydrologically Relevant\nFirst off, our plot is rather uninformative from hydrological perspective. A reasonable goal for this plot would be to aid the user to evaluate the distribution of annual river flow by province. In the above plot, the extreme values are stretching the scale too far out so let's limit our analysis to rivers that output less that 10,000 m^3^/s per year. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nannual_flow_sub <- annual_flow %>%\n  filter(annual_flow < 10000)\n```\n:::\n\n\nAlso the basic point plot doesn't give us a great way to look at the distribution. For that task, another of Claus's packages, `ggridges` comes in handy. `ggridges` is great for visualizing distributions and also forces us to flip the axes creating a more natural information flow (at least for those of us that read left to right). \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggridges)\n\nannual_flow_sub %>%\n  ggplot(aes(y = province, x = annual_flow)) +\n  geom_density_ridges() +\n  scale_y_discrete(name = NULL, labels = img_tags) +\n  theme(axis.text.y = element_markdown(color = 'black', size = 11))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\nA great line from Will's presentation pertained to white space:\n\n> White space is like garlic; take the amount you think you need, then triple it.\n\nRight then let's create some more white space by getting rid of the classic ggplot2 grey background. Here we can also tweak the height of the ridges to better show the distributions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nannual_flow_sub %>%\n  ggplot(aes(y = province, x = annual_flow)) +\n  geom_density_ridges(scale = 1) +\n  scale_y_discrete(name = NULL, labels = img_tags) +\n  theme_minimal() +\n  theme(axis.text.y = element_markdown(color = 'black', size = 11))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\nOk looking a bit better. Another one of Will's suggestion is to remove grid lines as much as possible. I basically agree and just keep the minor x values.\n \n\n::: {.cell}\n\n```{.r .cell-code}\nannual_flow_sub %>%\n  ggplot(aes(y = province, x = annual_flow)) +\n  geom_density_ridges(scale = 1) +\n  scale_y_discrete(name = NULL, labels = img_tags) +\n  theme_minimal() +\n  theme(axis.text.y = element_markdown(color = 'black', size = 11),\n        panel.grid.major = element_blank(),\n        panel.grid.minor.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n✔️ Now we need some colour here. As Will stated colour is hard. My goal here is pretty modest. I just want to distinguish between provinces. To do that I am actually going to steal some colour from the flags and manually map those to fill in colour for the ridges. At the same time I am going to add some transparency to the ridges. I am going to deviate a little from Will's advice here and keep the legend. I often get this way with plots and err on the side of caution. In this case I am thinking that folks won't recognize the flags and therefore will use the legend. In general though I do like the approach of forcing legends to justify their existence - they need to earn their keep.\n\n::: {.cell}\n\n```{.r .cell-code}\nflag_cols <- c('#3853a4',\n               '#f3ec18',\n               '#da1a33',\n               '#006b35',\n               '#0054a5')\n\nannual_flow_sub %>%\n  ggplot(aes(y = province, x = annual_flow, fill = province)) +\n  geom_density_ridges(scale = 1, alpha = 0.5) +\n  scale_fill_manual(values = flag_cols) +\n  scale_y_discrete(name = NULL, labels = img_tags) +\n  theme_minimal() +\n  theme(axis.text.y = element_markdown(color = 'black', size = 11),\n        panel.grid.major = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        legend.position = 'bottom',\n        legend.justification='right')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n\nLastly this plot needs a title, which according to Will's sage advice is also a great way to remove axes labels - just explain it in the title. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nannual_flow_sub %>%\n  ggplot(aes(y = province, x = annual_flow, fill = province)) +\n  geom_density_ridges(scale = 1, alpha = 0.5) +\n  scale_fill_manual(name = NULL, values = flag_cols) +\n  scale_y_discrete(name = NULL, labels = img_tags) +\n  labs(title = 'Smoothed distribution of annual flow of gauged rivers (m^3^ s^-1^) by province') +\n  theme_minimal() +\n  theme(axis.text.y = element_markdown(color = 'black', size = 11),\n        axis.title.x = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        plot.title.position = 'plot',\n        plot.title = element_markdown(size = 15), \n        legend.position = 'bottom',\n        legend.justification='right')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n\n\nFrom a visualization perspective this isn't perfect or even great. Legends are still problematic, I don't even know if the flags add anything and grid lines feel like an addiction. Still I think this does provide a decent overview of the types of rivers that are gauged in each province. Remembering that we previously subset all our river flow data to less than 10000, the Yukon gauges bigger rivers while Saskatchewan gauges many smaller rivers. BC and Newfoundland gauge a wide range of rivers types. Alberta gauges rivers that reflect both its mountain and prairies landscapes.\n\n## Back to RStudio conf\n\nThis has been a mini tour through some concept and packages I took in while attending RStudio::conf 2020. I can't wait to spend more time with these packages as they mature and development.  Every time I connect with the R community, I am grateful to be part of it. RStudio itself presents with class and respect all while creating a positive and inclusive space. I'm looking forward to future opportunities to connect with all you nerds!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}